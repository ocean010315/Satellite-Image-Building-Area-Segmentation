{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F # 추가\n",
    "\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from sklearn.model_selection import train_test_split#, KFold\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/osh9423/soohyun')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 디코딩 함수\n",
    "def rle_decode(mask_rle, shape):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)\n",
    "\n",
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False):\n",
    "        self.data = pd.read_csv(csv_file, keep_default_na=False)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx, 1]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) ### gray image(channel 1)\n",
    "\n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "\n",
    "        mask_rle = self.data.iloc[idx, 2]\n",
    "        \n",
    "        if mask_rle is None:\n",
    "            mask = [[0, 0, 0, 0],\n",
    "                    [0, 0, 0, 0],\n",
    "                    [0, 0, 0, 0],\n",
    "                    [0, 0, 0, 0]]\n",
    "        else:\n",
    "            mask = rle_decode(mask_rle, (image.shape[0], image.shape[1]))\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose(\n",
    "    [   \n",
    "        # A.Resize(224, 224),\n",
    "        A.RandomCrop(224, 224),\n",
    "        A.RandomRotate90(),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = SatelliteDataset(csv_file='./train1.csv', transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "\n",
    "# train_dataset, val_dataset = train_test_split(dataset, test_size=0.2, random_state=123)\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "# val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "def conv3x3(in_, out):\n",
    "    return nn.Conv2d(in_, out, (3, 3), padding=1)\n",
    "\n",
    "class ConvolutionReLu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvolutionReLu, self).__init__()\n",
    "        self.convolution = conv3x3(in_=in_channels, out=out_channels)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convolution(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels, is_deconvolution=True):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        if is_deconvolution:\n",
    "            self.block = nn.Sequential(\n",
    "                ConvolutionReLu(in_channels, middle_channels),\n",
    "                nn.ConvTranspose2d(\n",
    "                    middle_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=(4, 4),\n",
    "                    stride=(2, 2),\n",
    "                    padding=(1, 1),\n",
    "                ),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "        else:\n",
    "            self.block = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2, mode=\"bilinear\"),\n",
    "                ConvolutionReLu(in_channels, middle_channels),\n",
    "                ConvolutionReLu(middle_channels, out_channels),\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class AlBuNet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_classes=1,\n",
    "            num_filters=32, ###\n",
    "            pre_trained=True,\n",
    "            is_deconvolution=False, ###\n",
    "            res_net_to_use='resnet50',\n",
    "            # res_net_to_use='resnet34'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2) ###\n",
    "        self.encoder = getattr(models, res_net_to_use)(pretrained=True)\n",
    "\n",
    "        layers_features = [256, 512, 1024, 2048]\n",
    "        # layers_features = [64, 128, 256, 512]\n",
    "\n",
    "        self.non_linearity = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.convolution1 = nn.Sequential(\n",
    "            self.encoder.conv1, self.encoder.bn1, self.encoder.relu, nn.MaxPool2d(2, 2) ###\n",
    "        )\n",
    "\n",
    "        self.convolution2 = self.encoder.layer1\n",
    "        self.convolution3 = self.encoder.layer2\n",
    "        self.convolution4 = self.encoder.layer3\n",
    "        self.convolution5 = self.encoder.layer4\n",
    "\n",
    "        self.center = DecoderBlock(\n",
    "            layers_features[-1], num_filters*8*2, num_filters*8, is_deconvolution=True\n",
    "        )\n",
    "\n",
    "        self.dec5 = DecoderBlock(\n",
    "            layers_features[-1] + num_filters * 8,\n",
    "            num_filters*8*2,\n",
    "            num_filters*8,\n",
    "            is_deconvolution,\n",
    "        )\n",
    "        self.dec4 = DecoderBlock(\n",
    "            layers_features[-2] + num_filters * 8,\n",
    "            num_filters * 8 * 2,\n",
    "            num_filters * 8,\n",
    "            is_deconvolution,\n",
    "        )\n",
    "        self.dec3 = DecoderBlock(\n",
    "            layers_features[-3] + num_filters * 8,\n",
    "            num_filters * 4 * 2,\n",
    "            num_filters * 2,\n",
    "            is_deconvolution,\n",
    "        )\n",
    "        self.dec2 = DecoderBlock(\n",
    "            layers_features[-4] + num_filters * 2,\n",
    "            num_filters * 2 * 2,\n",
    "            num_filters * 2 * 2,\n",
    "            is_deconvolution,\n",
    "        )\n",
    "        self.dec1 = DecoderBlock(\n",
    "            num_filters * 2 * 2, num_filters * 2 * 2, num_filters, is_deconvolution\n",
    "        )\n",
    "        self.dec0 = ConvolutionReLu(num_filters, num_filters)\n",
    "        self.final = nn.Conv2d(num_filters, num_classes, kernel_size=(1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        convolution1 = self.convolution1(x)\n",
    "\n",
    "        convolution2 = self.convolution2(convolution1)\n",
    "        convolution3 = self.convolution3(convolution2)\n",
    "        convolution4 = self.convolution4(convolution3)\n",
    "        convolution5 = self.convolution5(convolution4)\n",
    "        \n",
    "        center = F.pad(self.center(self.pool(convolution5)), (0, 1, 0, 1)) # tensor size 맞춰야 해서 우측, 좌측에 각각 zero padding    \n",
    "\n",
    "        dec5 = self.dec5(torch.cat([center, convolution5], 1))\n",
    "        dec4 = self.dec4(torch.cat([dec5, convolution4], 1))\n",
    "        dec3 = self.dec3(torch.cat([dec4, convolution3], 1))\n",
    "        dec2 = self.dec2(torch.cat([dec3, convolution2], 1))\n",
    "        dec1 = self.dec1(dec2)\n",
    "        dec0 = self.dec0(dec1)\n",
    "\n",
    "        x_out = self.final(dec0)\n",
    "\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()\n",
    "print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3, 1), 'GB', 'Cached:', round(torch.cuda.memory_reserved(0)/1024**3, 1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 초기화\n",
    "model = AlBuNet().to(device)\n",
    "\n",
    "# loss function과 optimizer 정의\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer=optimizer,\n",
    "    lr_lambda=lambda epoch: 0.5 ** epoch,\n",
    "    last_epoch=-1,\n",
    "    verbose=False\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "# training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for images, masks in tqdm(dataloader):\n",
    "        images = images.float().to(device)\n",
    "        masks = masks.float().to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {epoch_loss/len(dataloader)}')\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './model/'\n",
    "# torch.save(model, PATH + 'model.pt')  # 전체 모델 저장\n",
    "torch.save(model.state_dict(), PATH + 'model_state_dict.pt')   # 모델 저장\n",
    "# torch.save({\n",
    "#     'model': model.state_dict(),\n",
    "#     'optimizer': optimizer.state_dict()\n",
    "# }, PATH + 'all.tar')  # 여러 가지 값 저장, 학습 중 진행 상황 저장을 위해 epoch, loss 값 등 일반 scalar값 저장 가능\n",
    "# model = ResUNet(in_channels, num_classes).to(device)\n",
    "# model.load_state_dict(torch.load(\"./model\"))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SatelliteDataset(csv_file='./test.csv', transform=transform, infer=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    result = []\n",
    "    for images in tqdm(test_dataloader):\n",
    "        images = images.float().to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        masks = torch.sigmoid(outputs).cpu().numpy()\n",
    "        masks = np.squeeze(masks, axis=1)\n",
    "        masks = (masks > 0.35).astype(np.uint8) # Threshold = 0.35\n",
    "\n",
    "        for i in range(len(images)):\n",
    "            mask_rle = rle_encode(masks[i])\n",
    "            if mask_rle == '': # 예측된 건물 픽셀이 아예 없는 경우 -1\n",
    "                result.append(-1)\n",
    "            else:\n",
    "                result.append(mask_rle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit['mask_rle'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('/home/osh9423/wonjun/submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
